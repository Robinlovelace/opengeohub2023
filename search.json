[
  {
    "objectID": "osm-slides.html#session-overview",
    "href": "osm-slides.html#session-overview",
    "title": "Tidy geographic data",
    "section": "Session overview",
    "text": "Session overview\n\nSource: pretalx.earthmonitor.org/opengeohub-summer-school-2023/schedule/v/0.7/"
  },
  {
    "objectID": "osm-slides.html#system-dependencies",
    "href": "osm-slides.html#system-dependencies",
    "title": "Tidy geographic data",
    "section": "System dependencies",
    "text": "System dependencies\n\nSource: Pebesma (2018)"
  },
  {
    "objectID": "osm-slides.html#development-environments",
    "href": "osm-slides.html#development-environments",
    "title": "Tidy geographic data",
    "section": "Development environments",
    "text": "Development environments"
  },
  {
    "objectID": "osm-slides.html#rstudio",
    "href": "osm-slides.html#rstudio",
    "title": "Tidy geographic data",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "osm-slides.html#vs-code",
    "href": "osm-slides.html#vs-code",
    "title": "Tidy geographic data",
    "section": "VS Code",
    "text": "VS Code"
  },
  {
    "objectID": "osm-slides.html#key-features-of-sf",
    "href": "osm-slides.html#key-features-of-sf",
    "title": "Tidy geographic data",
    "section": "Key features of sf",
    "text": "Key features of sf\n\nSource: Lovelace, Nowosad, and Muenchow (2019)"
  },
  {
    "objectID": "osm-slides.html#sf-functions",
    "href": "osm-slides.html#sf-functions",
    "title": "Tidy geographic data",
    "section": "sf functions",
    "text": "sf functions\n\nSource: Pebesma (2018)"
  },
  {
    "objectID": "osm-slides.html#sf-dplyr-workflow",
    "href": "osm-slides.html#sf-dplyr-workflow",
    "title": "Tidy geographic data",
    "section": "sf + dplyr workflow",
    "text": "sf + dplyr workflow\nMermaid graph:\ngraph LR\n  A[Read data] --&gt; B[Transform data]\n  B --&gt; C[Visualize data]"
  },
  {
    "objectID": "osm-slides.html#practical-1330-1430",
    "href": "osm-slides.html#practical-1330-1430",
    "title": "Tidy geographic data",
    "section": "Practical (~13:30-14:30)",
    "text": "Practical (~13:30-14:30)\nWork through the code at ogh23.robinlovelace.net/tidy and answer the questions at your own pace.\n\nremotes::install_cran(pkgs)\n\n\n# The packages we'll use\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"geos\",\n    \"data.table\",\n    \"spData\"\n)\nsapply(pkgs, require, character.only = TRUE)\n\n        sf  tidyverse       geos data.table     spData \n      TRUE       TRUE       TRUE       TRUE       TRUE"
  },
  {
    "objectID": "osm-slides.html#tidyverse-alternatives",
    "href": "osm-slides.html#tidyverse-alternatives",
    "title": "Tidy geographic data",
    "section": "tidyverse alternatives",
    "text": "tidyverse alternatives\n…"
  },
  {
    "objectID": "osm-slides.html#geos",
    "href": "osm-slides.html#geos",
    "title": "Tidy geographic data",
    "section": "geos",
    "text": "geos\n…"
  },
  {
    "objectID": "osm.html",
    "href": "osm.html",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "",
    "text": "This practical was developed for the OpenGeoHub summer school 2023.\nAs outlined in the session abstract, will cover\n\nHow and where to download OSM data\nHow to process small amounts of OSM data using the osmdata R package\nHow to process large OSM ‘extracts’ data with the osmextract R package\nOther command line tools for working with OSM data, including the mature and widely used osmium tool, the pyrosm Python package and the osm2streets web application and Rust codebase\n\nFinally, the session will outline ideas for using OSM data to support the fast and fair decarbonisation of the global economy."
  },
  {
    "objectID": "osm.html#uncompressed-osm-providers",
    "href": "osm.html#uncompressed-osm-providers",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "Uncompressed OSM providers",
    "text": "Uncompressed OSM providers\nQueries to Overpass API providers can be made directly from the Overpass Turbo web application, which has a convenient web interface that is ideal for exploring the data and writing queries iteratively.\nOverpass users the Overpass QL, an example of which is provided below. You can see the results of a query at this endpoint, for example: https://overpass-turbo.eu/?Q=%28%0A+++node%2851.249%2C7.148%2C51.251%2C7.152%29%3B%0A+++%3C%3B%0A%29%3B%0Aout+meta%3B\nThis can be written in Overpass QL as:\n(\n  node(51.249,7.148,51.251,7.152);\n  &lt;;\n);\nout meta;\nAfter saving this query as a file (e.g. called query.txt), you can download the data using the curl command line tool as follows:\ncurl -X POST -H \"Content-Type: application/x-www-form-urlencoded\" -d @query.txt https://overpass-api.de/api/interpreter &gt; data.osm\nAs outlined in the providers_comparison vignettte in the osmextract package, there are several providers of OSM data. The main ones that provide regular extracts without need for logins are:\n\ngeofabrik\nopenstreetmap_fr\nbbbike\n\n\nlibrary(osmextract)\n\nData (c) OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright.\nCheck the package website, https://docs.ropensci.org/osmextract/, for more details.\n\nlibrary(sf)\n\nLinking to GEOS 3.10.2, GDAL 3.4.1, PROJ 8.2.1; sf_use_s2() is TRUE\n\n\nExtracts from each provider are shown in the figures below, generated by code that can be ‘unfolded’ by clicking on the arrows:"
  },
  {
    "objectID": "osm.html#geofabrik",
    "href": "osm.html#geofabrik",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "Geofabrik",
    "text": "Geofabrik\ngeofabrik is a company that provides map-based services and free downloads of OSM extracts that are updated daily. These extracts are based on a division of the world into different regions, at 4 different levels. Zones in level 1 cover a whole continent (plus Russian Federation):\n\n\nCode\npar(mar = rep(0, 4))\nplot(geofabrik_zones[geofabrik_zones$level == 1, \"name\"], key.pos = NULL, main = NULL)\n\n\n\n\n\nLevel 2 contains polygons representing several countries all around the world:\n\n\nCode\nplot(geofabrik_zones[geofabrik_zones$level == 2, \"name\"], key.pos = NULL, main = NULL)\n\n\n\n\n\nGeofabrik also defines several special zones, such as Alps, Britain and Ireland, Germany, Austria and Switzerland, US Midwest, US Northeast, US Pacific, US South and US West (level 3). Moreover, it contains extracts relative to some administrative subregions, mainly in Europe, Russia, Canada and South America:\n\n\nCode\nplot(geofabrik_zones[geofabrik_zones$level == 3, \"name\"], key.pos = NULL, main = NULL)\n\n\n\n\n\nCheck ?geofabrik_zones and the provider’s webpage for more details."
  },
  {
    "objectID": "osm.html#openstreetmap.fr",
    "href": "osm.html#openstreetmap.fr",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "Openstreetmap.fr",
    "text": "Openstreetmap.fr\nopenstreetmap_fr extracts are taken from http://download.openstreetmap.fr/, a web-service that provides OSM data updated every few minutes. The extracts are based on several regions, such as the continents (level 1):\n\n\nCode\n# Russian federation is considered as a level 1 zone\nplot(openstreetmap_fr_zones[openstreetmap_fr_zones$level == 1, \"name\"], key.pos = NULL, main = NULL)\n\n\n\n\n\nor some countries around the world (less than geofabrik’s level 2 zones):\n\n\nCode\nplot(openstreetmap_fr_zones[openstreetmap_fr_zones$level == 2, \"name\"], key.pos = NULL, main = NULL)\n\n\n\n\n\nIt can be noticed that there are several holes (such as Peru, which is the reason why, in the first example, Lima was matched with South America data), implying that openstreetmap_fr cannot always be used for geographical matching of a place. Nevertheless, it provides extremely detailed extracts for some regions of the world, like China,\n\n\nCode\nplot(openstreetmap_fr_zones[openstreetmap_fr_zones$parent == \"china\", \"name\"], key.pos = NULL, main = NULL)\n\n\n\n\n\nIndia,\n\n\nCode\nplot(openstreetmap_fr_zones[openstreetmap_fr_zones$parent == \"india\", \"name\"], key.pos = NULL, main = NULL)\n\n\n\n\n\nFrance,\n\n\nCode\nids_2 = openstreetmap_fr_zones$parent %in% \"france\"\nids_3 = openstreetmap_fr_zones$parent %in% openstreetmap_fr_zones$id[ids_2]\n\nplot(openstreetmap_fr_zones[ids_2 | ids_3, \"name\"], key.pos = NULL, main = NULL)\n\n\n\n\n\nand Brazil\n\n\nCode\nids_2 = openstreetmap_fr_zones$parent %in% \"brazil\"\nids_3 = openstreetmap_fr_zones$parent %in% openstreetmap_fr_zones$id[ids_2]\n\nplot(openstreetmap_fr_zones[ids_2 | ids_3, \"name\"], key.pos = NULL, main = NULL)"
  },
  {
    "objectID": "osm.html#bbbike",
    "href": "osm.html#bbbike",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "BBBike",
    "text": "BBBike\nbbbike provider is based on https://download.bbbike.org/osm/bbbike/. It is quite different from any other provider supported in osmextract since it contains OSM data for more than 200 cities worldwide.\n\nbbbike provider is the safest choice if you are looking for OSM data relative to a particular city in the world."
  },
  {
    "objectID": "osm.html#finding-an-extract-to-download",
    "href": "osm.html#finding-an-extract-to-download",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "Finding an extract to download",
    "text": "Finding an extract to download\nLet’s see how it works for the city of Poznan:\nWe geocode the coordinates of Poznan, Poland\n\npoznan = tmaptools::geocode_OSM(\"Poznan, Poland\")$coords\n# poznan = c(x = 16.933, y = 52.408)\n\nand look for a match in the OSM extracts using oe_match():\n\noe_match(poznan, provider = \"geofabrik\")\n\n$url\n[1] \"https://download.geofabrik.de/europe/poland/wielkopolskie-latest.osm.pbf\"\n\n$file_size\n[1] 1.26e+08\n\noe_match(poznan, provider = \"bbbike\")\n\n$url\n[1] \"https://download.bbbike.org/osm/bbbike/Poznan/Poznan.osm.pbf\"\n\n$file_size\n[1] 25856507\n\noe_match(poznan, provider = \"openstreetmap_fr\")\n\n$url\n[1] \"http://download.openstreetmap.fr/extracts/europe/poland/wielkopolskie-latest.osm.pbf\"\n\n$file_size\n[1] 143404382\n\n\nAs shown above, bbbike is the only provide that provides a match for Poznan (the others match with all of Poland)."
  },
  {
    "objectID": "osm.html#downloading-the-extract",
    "href": "osm.html#downloading-the-extract",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "Downloading the extract",
    "text": "Downloading the extract\nWe can download the extract using oe_get(), noting the user of layer = \"points\" to get the points layer of the OSM data:\n\npoznan = oe_get(\"Poznan\", provider = \"bbbike\", force_vectortranslate = TRUE)\n\nNote: that takes quite a while download, so we will use a smaller extract for the rest of the session:\n\nmonaco_osm_points = oe_get(\"monaco\", provider = \"bbbike\", layer = \"points\")\n\nNo exact match found for place = monaco and provider = bbbike. Best match is Moscow. \nChecking the other providers.\n\n\nAn exact string match was found using provider = geofabrik.\n\n\nDownloading the OSM extract:\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |=====================                                                 |  31%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |==============================                                        |  44%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |========================================================              |  81%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |=================================================================     |  94%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n\n\nFile downloaded!\n\n\nStarting with the vectortranslate operations on the input file!\n\n\n0...10...20...30...40...50...60...70...80...90...100 - done.\n\n\nFinished the vectortranslate operations on the input file!\n\n\nReading layer `points' from data source \n  `/tmp/RtmpgRsIIx/geofabrik_monaco-latest.gpkg' using driver `GPKG'\nSimple feature collection with 3041 features and 10 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7.408202 ymin: 43.51654 xmax: 7.500245 ymax: 43.75175\nGeodetic CRS:  WGS 84\n\n\n\n# ?oe_get\nmonaco_osm_lines = oe_get(\"monaco\", provider = \"bbbike\", layer = \"lines\", skip_vectortranslate = TRUE)\nf = list.files(oe_download_directory(), pattern = \"monaco\", full.names = TRUE)\nmonaco = sf::read_sf(f[1])\nmonaco = sf::read_sf(f[2], layer = \"lines\")\nmonaco_osm_mlines = oe_get(\"monaco\", provider = \"bbbike\", layer = \"multilinestrings\")\nmonaco_osm_polygons = oe_get(\"monaco\", provider = \"bbbike\", layer = \"multipolygons\")\nmonaco_osm_other = oe_get(\"monaco\", provider = \"bbbike\", layer = \"other_relations\")\n\nLet’s take a look at the size of each layer, in units of MB:\n\n\nCode\nsizes_mb = sapply(list(monaco_osm_points, monaco_osm_lines, monaco_osm_mlines, monaco_osm_polygons, monaco_osm_other), function(x) {\n    round(object.size(x) / 1e6, 1)\n})\nlayer_names = c(\"points\", \"lines\", \"multilinestrings\", \"multipolygons\", \"other_relations\")\nn_features = sapply(list(monaco_osm_points, monaco_osm_lines, monaco_osm_mlines, monaco_osm_polygons, monaco_osm_other), nrow)\nsize_df = data.frame(\n  layer = layer_names,\n  size_mb = sizes_mb,\n  n_features = n_features,\n  kb_per_feature = sizes_mb / n_features * 1e3\n)\nknitr::kable(size_df)\n\n\n\n\n\nlayer\nsize_mb\nn_features\nkb_per_feature\n\n\n\n\npoints\n2.0\n3041\n0.6576784\n\n\nlines\n2.7\n3023\n0.8931525\n\n\nmultilinestrings\n1.1\n61\n18.0327869\n\n\nmultipolygons\n2.1\n1699\n1.2360212\n\n\nother_relations\n0.3\n100\n3.0000000"
  },
  {
    "objectID": "osm.html#exercises",
    "href": "osm.html#exercises",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "Exercises",
    "text": "Exercises\n\nCreate maps of the different layers using {tmap}, {ggplot2} or a mapping package of your choice.\nWhich layer is most interesting for your research?\nAre there any phenomena that are represented in more than one layer and, if so, thoughts on how to combine them?"
  },
  {
    "objectID": "osm.html#pyrosm",
    "href": "osm.html#pyrosm",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "pyrosm",
    "text": "pyrosm\nInstall the Python package pyrosm as follows:\npip install pyrosm\n\nSearch for Poznan in extracts available from pyrosm as follows (note: this fails for me currently as documented in github.com/HTenkanen/pyrosm/issues/217):\n\nimport pyrosm\nfrom pyrosm import OSM\nimport geopandas as gpd\n\npoznan_file = pyrosm.get_data(\"Poznan\")\nosm = OSM(poznan_file)\npoznan_cycling = osm.get_network(network_type=\"cycling\")\npoznan_cycling.plot()"
  },
  {
    "objectID": "osm.html#osmnx",
    "href": "osm.html#osmnx",
    "title": "Processing large OpenStreetMap datasets for research",
    "section": "osmnx",
    "text": "osmnx\nInstall the Python package osmnx as follows:\npip install osmnx\n\nimport osmnx as ox\n\n/home/runner/.virtualenvs/r-reticulate/lib/python3.10/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n  warnings.warn(\n\nimport pandas as pd\nimport geopandas as gpd\n# Get cycle netework for Poznan\npoznan_polygon = ox.geocode_to_gdf(\"Poznan, Poland\")\npoznan_polygon.plot();\n\n\n\n\nThat is quite a big network, so let’s get the area of the polygon and use that to get a smaller network from GitHub:\n\n# Get data from https://github.com/Robinlovelace/opengeohub2023/raw/main/pois_buffer_simple.geojson:\npoznan_small = gpd.read_file(\"https://github.com/Robinlovelace/opengeohub2023/raw/main/pois_buffer_simple.geojson\")\npoznan_small.plot();\n\n\n\n\nDownload the cycling network as follows:\n\nG_cycle = ox.graph_from_polygon(poznan_small.geometry[0], network_type=\"bike\")\n\nPlot the results:\n\nox.plot_graph(G_cycle)\n\n\n\n\nGet basic stats as follows:\n\narea = ox.project_gdf(poznan_small).unary_union.area\nstats = ox.basic_stats(G_cycle, area=area)\npd.Series(stats)\n\nn                                                                             568\nm                                                                            1467\nk_avg                                                                    5.165493\nedge_length_total                                                      101250.782\nedge_length_avg                                                         69.018938\nstreets_per_node_avg                                                     2.707746\nstreets_per_node_counts                 {0: 0, 1: 126, 2: 1, 3: 355, 4: 85, 5: 1}\nstreets_per_node_proportions    {0: 0.0, 1: 0.22183098591549297, 2: 0.00176056...\nintersection_count                                                            442\nstreet_length_total                                                     51276.381\nstreet_segment_count                                                          749\nstreet_length_avg                                                       68.459788\ncircuity_avg                                                             1.041883\nself_loop_proportion                                                      0.00267\nnode_density_km                                                         178.71231\nintersection_density_km                                                139.068382\nedge_density_km                                                      31856.973767\nstreet_density_km                                                    16133.310698\ndtype: object\n\n\nCalculate the centrality across the network as follows:\nWe can convert the object into a ‘GeoDataFrame’ as follows:\n\ncycle_gdf = ox.graph_to_gdfs(G_cycle, edges=True)"
  },
  {
    "objectID": "tidy.html",
    "href": "tidy.html",
    "title": "Tidy geographic data",
    "section": "",
    "text": "These materials were created for the OpenGeoHub Summer School 2023.\nThey can be used with reference to the accompanying slides, available at ogh23.robinlovelace.net/opengeohub2023.\nSee the parent repo and session description in the agenda for context."
  },
  {
    "objectID": "tidy.html#learning-objectives",
    "href": "tidy.html#learning-objectives",
    "title": "Tidy geographic data",
    "section": "1.1 Learning objectives",
    "text": "1.1 Learning objectives\nBy the end of the session, participants will be able to:\n\nRead, write, manipulate, and plot geographic data using the sf package\nUse the tidyverse metapackage to speed-up the writing of geographic data analysis pipelines\nUse the geos package to perform geometric operations on geographic data\nUnderstand the strengths and weaknesses of the tidyverse for geographic data analysis"
  },
  {
    "objectID": "tidy.html#prerequisites",
    "href": "tidy.html#prerequisites",
    "title": "Tidy geographic data",
    "section": "1.2 Prerequisites",
    "text": "1.2 Prerequisites\nWe recommend you run the code in the practical session with a modern integrated development environment (IDE) such as\n\nRStudio: an IDE focussed on data science and software development with R. See posit.co for installation instructions.\nVS Code: a general purpose, popular and future-proof IDE with support for R. See github.com/REditorSupport/vscode-R and quarto.org for installation instructions.\n\nAfter you have installed a suitable IDE you will need to install R packages used in this tutorial. You can install the packages we’ll use with the following commands:\n\n# Install remotes if not already installed\nif (!requireNamespace(\"remotes\")) {\n    install.packages(\"remotes\")\n}\n\n# The packages we'll use\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"geos\",\n    \"ggspatial\",\n    \"spData\"\n)\n\n\nremotes::install_cran(pkgs)\n\nAfter running the above commands, you should be able to load the packages with the following command (we will load the packages individually in subsequent sections):\n\nsapply(pkgs, require, character.only = TRUE)"
  },
  {
    "objectID": "tidy.html#reading-and-writing-geographic-data",
    "href": "tidy.html#reading-and-writing-geographic-data",
    "title": "Tidy geographic data",
    "section": "2.1 Reading and writing geographic data",
    "text": "2.1 Reading and writing geographic data\nYou can read and write a wide range of vector geographic data with sf. Save the countries object to a file called countries.geojson and inspect the result.\n\nsf::write_sf(countries, \"countries.geojson\", delete_dsn = TRUE)\n\nYou can read the file in again with read_sf() (which returns a ‘tidyverse compliant’ tibble data frame) or st_read(), as shown below.\n\ncountries_new1 = sf::read_sf(\"countries.geojson\")\ncountries_new2 = sf::st_read(\"countries.geojson\")\n\nReading layer `countries' from data source \n  `/home/runner/work/opengeohub2023/opengeohub2023/countries.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 4 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 12.24011 ymin: 47.75843 xmax: 26.58828 ymax: 56.37253\nGeodetic CRS:  WGS 84\n\n\nFor most purposes the two representations are the same, although the ‘tibble’ version’s print outpout is slightly different.\n\ncountries_new1 |&gt;\n  head(2)\n\nSimple feature collection with 2 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 14.07452 ymin: 49.0274 xmax: 26.58828 ymax: 56.37253\nGeodetic CRS:  WGS 84\n# A tibble: 2 × 11\n  iso_a2 name_long continent region_un subregion   type  area_km2    pop lifeExp\n  &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 PL     Poland    Europe    Europe    Eastern Eu… Sove…  310402. 3.80e7    77.6\n2 LT     Lithuania Europe    Europe    Northern E… Sove…   63831. 2.93e6    74.5\n# ℹ 2 more variables: gdpPercap &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\ncountries_new2 |&gt;\n  head(2)\n\nSimple feature collection with 2 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 14.07452 ymin: 49.0274 xmax: 26.58828 ymax: 56.37253\nGeodetic CRS:  WGS 84\n  iso_a2 name_long continent region_un       subregion              type\n1     PL    Poland    Europe    Europe  Eastern Europe Sovereign country\n2     LT Lithuania    Europe    Europe Northern Europe Sovereign country\n   area_km2      pop  lifeExp gdpPercap                       geometry\n1 310402.33 38011735 77.60244  24347.07 MULTIPOLYGON (((23.48413 53...\n2  63831.09  2932367 74.51707  26258.21 MULTIPOLYGON (((26.49433 55...\n\n\nA nice function to explore the differences between the two objects is waldo::compare(). It shows that, other than their classes, the two objects are identical:\n\nwaldo::compare(countries_new1, countries_new2)\n\n`class(old)`: \"sf\" \"tbl_df\" \"tbl\" \"data.frame\"\n`class(new)`: \"sf\"                \"data.frame\"\n\n\nSee the full list of file formats that you can read and write with sf with the following commands:\n\ndrvs = sf::st_drivers() |&gt;\n  as_tibble()\nhead(drvs)\n\n# A tibble: 6 × 7\n  name   long_name                       write copy  is_raster is_vector vsi  \n  &lt;chr&gt;  &lt;chr&gt;                           &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;     &lt;lgl&gt;     &lt;lgl&gt;\n1 ESRIC  Esri Compact Cache              FALSE FALSE TRUE      TRUE      TRUE \n2 FITS   Flexible Image Transport System TRUE  FALSE TRUE      TRUE      FALSE\n3 PCIDSK PCIDSK Database File            TRUE  FALSE TRUE      TRUE      TRUE \n4 netCDF Network Common Data Format      TRUE  TRUE  TRUE      TRUE      TRUE \n5 PDS4   NASA Planetary Data System 4    TRUE  TRUE  TRUE      TRUE      TRUE \n6 VICAR  MIPL VICAR file                 TRUE  TRUE  TRUE      TRUE      TRUE \n\n\n\n2.1.1 Exercises\n\nRe-create the country_centroids object, using world_centroids and poland and inputs, but this time using base R syntax with the [ operator.\n\nBonus: use the bench::mark() function to compare the performance of the base R and tidyverse implementation\nOpen question: Is this a good thing to benchmark? Why or why not?\n\n\n\nInspect the full list of drivers, e.g. with the command View(drvs).\n\nWhich formats are you likely to use and why?\nBonus: take a look at Chapter 8 of Geocomputation with R for more on reading and writing geographic (including raster) data with R."
  },
  {
    "objectID": "tidy.html#attribute-operations-with-dplyr",
    "href": "tidy.html#attribute-operations-with-dplyr",
    "title": "Tidy geographic data",
    "section": "2.2 Attribute operations with dplyr",
    "text": "2.2 Attribute operations with dplyr\ndplyr is a large package with many functions for working with data frames. The five key ‘verbs’ described as:\n\n\nmutate() adds new variables that are functions of existing variables\nselect() picks variables based on their names.\nfilter() picks cases based on their values.\nsummarise() reduces multiple values down to a single summary.\narrange() changes the ordering of the rows.\n\n\nLet’s take a brief look at each.\n\ncountries_modified = countries |&gt;\n  mutate(pop_density = pop / area_km2) |&gt;\n  select(name_long, pop_density) |&gt;\n  filter(pop_density &gt; 100) |&gt;\n  arrange(desc(pop_density))\ncountries_modified\n\nSimple feature collection with 3 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 12.24011 ymin: 47.75843 xmax: 24.02999 ymax: 54.85154\nGeodetic CRS:  WGS 84\n# A tibble: 3 × 3\n  name_long      pop_density                                                geom\n  &lt;chr&gt;                &lt;dbl&gt;                                  &lt;MULTIPOLYGON [°]&gt;\n1 Czech Republic        130. (((15.017 51.10667, 14.57072 51.00234, 14.30701 51…\n2 Poland                122. (((23.48413 53.9125, 23.24399 54.22057, 22.7311 54…\n3 Slovakia              115. (((22.55814 49.08574, 21.60781 49.47011, 20.88796 …\n\n\nThe summarise() function is often used in combination with group_by(), e.g. as follows:\n\ncountries_summarised = countries |&gt;\n  group_by(contains_a = str_detect(name_long, \"a\")) |&gt;\n  summarise(n = n(), mean_pop = mean(pop))\ncountries_summarised\n\nSimple feature collection with 2 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 12.24011 ymin: 47.75843 xmax: 26.58828 ymax: 56.37253\nGeodetic CRS:  WGS 84\n# A tibble: 2 × 4\n  contains_a     n  mean_pop                                                geom\n  &lt;lgl&gt;      &lt;int&gt;     &lt;dbl&gt;                                       &lt;POLYGON [°]&gt;\n1 FALSE          1 10525347  ((15.017 51.10667, 14.57072 51.00234, 14.30701 51.…\n2 TRUE           3 15454250. ((26.49433 55.61511, 25.53305 56.1003, 25.00093 56…\n\n\nThe operation creates a new variable called contains_a that is TRUE if the country name contains an “a” and FALSE otherwise. Perhaps more impressively, it also automatically updated the geometry column of the combined countries containing the letter “a”, highlighting dplyr’s ability to work with geographic data represented as sf objects.\n\ncountries_summarised |&gt;\n  ggplot() +\n    geom_sf(aes(fill = contains_a)) +\n    geom_sf(data = countries, fill = NA, linetype = 3) \n\n\n\n\nFigure 2: Result of running dplyr group_by() and summarise() functions on countries data\n\n\n\n\n\n2.2.1 Exercises\n\nCreate a new data frame called countries_modified2 that contains the name, population and area of countries with a population density of more than 100 people per km2, sorted by area in descending order.\nDo the same with base R functions and the [ operator.\n\nWhat are the pros and cons of each?\nWhich do you prefer?"
  },
  {
    "objectID": "tidy.html#making-maps-with-ggplot2",
    "href": "tidy.html#making-maps-with-ggplot2",
    "title": "Tidy geographic data",
    "section": "2.3 Making maps with ggplot2",
    "text": "2.3 Making maps with ggplot2\nAs shown above, geom_sf() works ‘out of the box’ with geographic data. We can modify plotting commands to control outputs as showing in Figure 3 and generate publishable maps.\n\nlibrary(ggspatial)\ncountries |&gt;\n  ggplot() +\n    geom_sf(fill = \"grey80\", color = \"black\") +\n    geom_sf(data = countries_modified, aes(fill = pop_density)) +\n    scale_fill_viridis_c() +\n    theme_minimal()\n\n\n\n\nFigure 3: Map created with ggplot2, with fill color controlled by the pop_density variable and multiple layers.\n\n\n\n\nMap making is an iterative and time consuming process. Iterate on the code above, e.g. by changing the color palette, adding a title, and adding a legend.\nThere are many add-ons to ggplot2. ggspatial can be used to add a basemap to a plot with annotation_map_tile(), as illustrated in Figure 4.\n\nrosm::osm.types()\n\n [1] \"osm\"                    \"opencycle\"              \"hotstyle\"              \n [4] \"loviniahike\"            \"loviniacycle\"           \"stamenbw\"              \n [7] \"stamenwatercolor\"       \"osmtransport\"           \"thunderforestlandscape\"\n[10] \"thunderforestoutdoors\"  \"cartodark\"              \"cartolight\"            \n\nggplot() +\n  annotation_map_tile() +\n  layer_spatial(countries_modified, aes(fill = pop_density),\n                linewidth = 3, alpha = 0.3) +\n  scale_fill_viridis_c()\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |======================================================================| 100%\n\n\n\n\n\nFigure 4: Map created with ggplot2, with a basemap added with annotation_map_tile().\n\n\n\n\n\n2.3.1 Exercises\n\nWith reference to the documentation at ggplot2.tidyverse.org/index.html, modify the code above to create a map with a title, legend and a different color palette.\nWith reference to paleolimbot.github.io/ggspatial/, add annotations including scale bar, north arrow and a text label to the map.\nBonus: try map making with tmap and test out the interactive mode (set with tmap_mode(\"interactive\")).”\nBonus: try reproducing maps presented in Chapter 9 of Geocomputation with R with ggplot2 and ggspatial. Which mapping framework do you prefer and why?\nIf you use raster data, take a look at the tidyterra documentation."
  },
  {
    "objectID": "tidy.html#loading-a-gpx-file",
    "href": "tidy.html#loading-a-gpx-file",
    "title": "Tidy geographic data",
    "section": "3.1 Loading a GPX file",
    "text": "3.1 Loading a GPX file\nLet’s load a GPX file representing a route from the Faculty to FairPlayce.\n\nu_gpx = \"https://www.openstreetmap.org/trace/9741677/data\"\nf_gpx = paste0(basename(u_gpx), \".gpx\")\ndownload.file(u_gpx, f_gpx)\nsf::st_layers(f_gpx)\n\nDriver: GPX \nAvailable layers:\n    layer_name     geometry_type features fields crs_name\n1    waypoints             Point        0     23   WGS 84\n2       routes       Line String        0     12   WGS 84\n3       tracks Multi Line String        1     12   WGS 84\n4 route_points             Point        0     25   WGS 84\n5 track_points             Point     1525     29   WGS 84\n\ngpx = sf::read_sf(f_gpx, layer = \"track_points\")\n\nWe can divide the GPS points into n groups of equal length as follows:\n\ngpx_mutated = gpx |&gt;\n  mutate(minute = lubridate::round_date(time, \"minute\")) |&gt;\n  mutate(second = lubridate::round_date(time, \"second\")) \nsummary(gpx_mutated$minute)\n\n                      Min.                    1st Qu. \n\"2023-08-27 08:02:00.0000\" \"2023-08-27 08:20:00.0000\" \n                    Median                       Mean \n\"2023-08-27 08:36:00.0000\" \"2023-08-27 08:38:42.8065\" \n                   3rd Qu.                       Max. \n\"2023-08-27 08:59:00.0000\" \"2023-08-27 09:14:00.0000\" \n\n\nLet’s create an animated map, as illustrated in Figure 6, with the following code:\n\n# ?tmap_animation\nm_faceted = m_osm +\n  tm_shape(gpx_mutated[pois_buffer, ]) +\n  tm_dots(size = 0.8, legend.show = FALSE) +\n  tm_facets(\"second\", free.coords = FALSE, ncol = 1, nrow = 1) +\n  tm_scale_bar()\ntmap_animation(m_faceted, delay = 2, filename = \"gpx.gif\")\n\n\n\n\n\nFigure 6: Animated map of a GPX file representing a route from central Poznan to FairPlayce."
  },
  {
    "objectID": "tidy.html#exercises-3",
    "href": "tidy.html#exercises-3",
    "title": "Tidy geographic data",
    "section": "3.2 Exercises",
    "text": "3.2 Exercises\n\nCreate sf objects representing the following features in Poznan (hint: try using functions for geocoding such as stplanr::geo_code() or tmaptools::geocode_OSM()):\n\nThe main train station\nThe airport\n\nIdentify interesting features in the surrounding area from OSM and plot them in static and interactive maps."
  },
  {
    "objectID": "tidy.html#finding-suitable-coordinate-reference-systems",
    "href": "tidy.html#finding-suitable-coordinate-reference-systems",
    "title": "Tidy geographic data",
    "section": "4.1 Finding suitable coordinate reference systems",
    "text": "4.1 Finding suitable coordinate reference systems\ngeos is designed to work with projected data, so we will reproject the countries object to a different CRS before proceeding.\n\nsuitable_crs = crsuggest::suggest_crs(countries)\nsuitable_crs\n\n# A tibble: 10 × 6\n   crs_code crs_name                        crs_type crs_gcs crs_units crs_proj4\n   &lt;chr&gt;    &lt;chr&gt;                           &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n 1 3328     Pulkovo 1942(58) / GUGiK-80     project…    4179 m         +proj=st…\n 2 2180     ETRF2000-PL / CS92              project…    9702 m         +proj=tm…\n 3 3120     Pulkovo 1942(58) / Poland zone… project…    4179 m         +proj=st…\n 4 2173     Pulkovo 1942(58) / Poland zone… project…    4179 m         +proj=st…\n 5 2172     Pulkovo 1942(58) / Poland zone… project…    4179 m         +proj=st…\n 6 2177     ETRF2000-PL / CS2000/18         project…    9702 m         +proj=tm…\n 7 2178     ETRF2000-PL / CS2000/21         project…    9702 m         +proj=tm…\n 8 8353     S-JTSK [JTSK03] / Krovak East … project…    8351 m         +proj=kr…\n 9 8352     S-JTSK [JTSK03] / Krovak        project…    8351 m         +proj=kr…\n10 5514     S-JTSK / Krovak East North      project…    4156 m         +proj=kr…\n\n\nWe’ll use the second of these, EPSG:2180, after checking (the package’s top suggestion is not always the most up-to-date or appropriate option).\n\ncrs1 = paste0(\"EPSG:\", suitable_crs$crs_code[2])\ncrs1\n\n[1] \"EPSG:2180\"\n\ncountries_projected = sf::st_transform(countries, crs = crs1)\n\n\ncountries_geos = as_geos_geometry(sf::st_geometry(countries_projected))\ncountries_geos\n\n&lt;geos_geometry[4] with CRS=ETRF2000-PL / CS92&gt;\n[1] &lt;MULTIPOLYGON [169518 135742...854986 777315]&gt;\n[2] &lt;MULTIPOLYGON [628064 681310...982752 961090]&gt;\n[3] &lt;MULTIPOLYGON [343349 -11504...759703 189400]&gt;\n[4] &lt;MULTIPOLYGON [18570 83048...489369 371643]&gt;  \n\n\nThe package only deals with geometries: the attribute data is removed when you convert an sf object to a geos object. You can store geos objects in a data frame and still use dplyr functions to process them:\n\ncountries_geos_df = bind_cols(countries_df, geos = countries_geos)\ncountries_summarised_df = countries_geos_df |&gt;\n  group_by(contains_a = str_detect(name_long, \"a\")) |&gt;\n  summarise(n = n(), mean_pop = mean(pop))\ncountries_summarised_df\n\n# A tibble: 2 × 3\n  contains_a     n  mean_pop\n  &lt;lgl&gt;      &lt;int&gt;     &lt;dbl&gt;\n1 FALSE          1 10525347 \n2 TRUE           3 15454250.\n\n\nNote: the geos column has gone! This is because geos columns are not ‘sticky’ like sf columns. Let’s see how to get them back.\n\ncountries_union1 = countries_geos |&gt;\n  geos_unary_union()\nplot(countries_union1)\ncountries_union2 = countries_geos |&gt;\n  geos_make_collection() |&gt;\n  geos_unary_union()\nplot(countries_union2)\n\n\n\n\n\n\n\n\n\n\n\nHowever, you can add the union of the grouped columns as follows:\n\ncountries_summarised_geos = countries_geos_df |&gt;\n  group_by(contains_a = str_detect(name_long, \"a\")) |&gt;\n  summarise(n = n(), mean_pop = mean(pop),\n  geometry = geos_unary_union(geos_make_collection(geos)))\ncountries_summarised_geos\n\n# A tibble: 2 × 4\n  contains_a     n  mean_pop geometry                                 \n  &lt;lgl&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;geos_geom&gt;                              \n1 FALSE          1 10525347  &lt;POLYGON [18570 83048...489369 371643]&gt;  \n2 TRUE           3 15454250. &lt;POLYGON [169518 -11504...982752 961090]&gt;\n\nplot(countries_summarised_geos$geometry)\n\n\n\n\nConvert back to an sf object as follows:\n\ncountries_summarised_geos_sf = st_as_sf(countries_summarised_geos)\n# waldo::compare(\n#   countries_summarised,\n#   countries_summarised_geos_sf\n#   )\n\nAside from geometry names and minor differences in the geometries, the two objects are identical. This raises the question: why use geos at all? The answer can be found by following the exercises below."
  },
  {
    "objectID": "tidy.html#exercises-4",
    "href": "tidy.html#exercises-4",
    "title": "Tidy geographic data",
    "section": "4.2 Exercises",
    "text": "4.2 Exercises\n\nBenchmark the union operation in geos and sf with the bench::mark() function.\n\nWhich is faster?\nWhich is easier to use?\nWhich do you prefer?"
  },
  {
    "objectID": "tidy.html#getting-and-reading-in-the-data",
    "href": "tidy.html#getting-and-reading-in-the-data",
    "title": "Tidy geographic data",
    "section": "5.1 Getting and reading-in the data",
    "text": "5.1 Getting and reading-in the data\nTo get the data for this session, download and unzip the data.zip file in the releases. You can do that in R with the following commands:\n\nu = \"https://github.com/Robinlovelace/opengeohub2023/releases/download/data/data.zip\"\nf = basename(u)\nif (!dir.exists(\"data\")) {\n  download.file(u, f)\n  unzip(f)\n}\n\nCheck you have downloaded the files with the following command:\n\nlist.files(\"data\")[1:3]\n\n[1] \"gtfs\" \"hls\"  \"osm\""
  },
  {
    "objectID": "tidy.html#vector-data",
    "href": "tidy.html#vector-data",
    "title": "Tidy geographic data",
    "section": "5.2 Vector data",
    "text": "5.2 Vector data\nLet’s start by reading-in a dataset representing transport-related features around Poznan (note: you need to have downloaded and unzipped the data.zip file into your project or working directory for this to work):\n\npol_all = sf::read_sf(\"./data/osm/gis_osm_transport_a_free_1.shp\")\npol_all\n\nSimple feature collection with 282 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 15.76877 ymin: 51.42587 xmax: 18.51031 ymax: 53.52821\nGeodetic CRS:  WGS 84\n# A tibble: 282 × 5\n   osm_id    code fclass          name                                  geometry\n   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;                            &lt;POLYGON [°]&gt;\n 1 27923283  5656 apron           &lt;NA&gt;                 ((16.84088 52.42479, 16.…\n 2 28396243  5656 apron           &lt;NA&gt;                 ((16.9675 52.32743, 16.9…\n 3 28396249  5656 apron           &lt;NA&gt;                 ((16.98029 52.32399, 16.…\n 4 28396250  5656 apron           &lt;NA&gt;                 ((16.97407 52.32418, 16.…\n 5 30164579  5656 apron           &lt;NA&gt;                 ((16.71011 53.16458, 16.…\n 6 32225811  5601 railway_station Czerwonak            ((16.9798 52.46868, 16.9…\n 7 36204378  5622 bus_station     &lt;NA&gt;                 ((16.95469 52.40964, 16.…\n 8 50701732  5651 airport         Lądowisko Poznań-Be… ((17.19788 52.53491, 17.…\n 9 55590985  5622 bus_station     Dworzec PKS-stanowi… ((17.20243 52.80927, 17.…\n10 56064358  5651 airport         Port lotniczy Zielo… ((15.76877 52.13175, 15.…\n# ℹ 272 more rows\n\n\nLet’s filter-out a feature that matches a particular character string:\n\npol = pol_all |&gt;\n  filter(str_detect(name, \"Port*.+Poz\"))\n\nPlot it, first with base R and then with {ggplot2}and {tmap}, resulting in maps shown below.\n\nplot(pol)\npol |&gt;\n  ggplot() +\n  geom_sf()\ntm_shape(pol) + tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ll read-in a point layer from a CSV file as shown below.\n\nstops_raw = read_csv('data/gtfs/stops.txt')\n\nRows: 2921 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): stop_code, stop_name, zone_id\ndbl (3): stop_id, stop_lat, stop_lon\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstops_df = stops_raw |&gt;\n  select(-stop_code)\nstops = st_as_sf(stops_df, coords = c(\"stop_lon\", \"stop_lat\"), crs = \"EPSG:4326\")\n\n\n5.2.1 Buffers\nThe most widly used way to create buffers in R is with the function st_buffer() from the sf package. Let’s create buffers of 150 m around each of the points in the poi_sf dataset. This is done in the following chunk, which first checks to see if the s2 spherical geometry engine is set to run (it is by default).\n\nsf::sf_use_s2()\n\n[1] TRUE\n\npoi_buffers = st_buffer(poi_sf, dist = 150)\n\nAs described in Chapter 7 or Geocomputation with R, sf ‘knows that the world is round’ and uses a spherical geometry engine to calculate distances for unprojected data. This is a major advantage of sf over other packages for working with geographic data, such as GeoPandas in Python, which does not currently support spherical geometry operations (see issue 2098 in the GeoPandas issue tracker for details).\nWe can measure the area of the buffers with the following command:\n\nareas = st_area(poi_buffers)\n\nA nice feature of sf is that it returns the area in square meters, even though the input data is in degrees. sf uses the units package behind the scenes to convert between units, meaning you can convert the output to different units, as shown below.\n\nareas |&gt;\n  units::set_units(ha)\n\nUnits: [ha]\n[1] 7.165668 7.164428 7.165692 7.166715\n\n\nSometimes it’s useful to drop the units class, which can be done with the units::drop_units() function, as shown below.\n\nareas |&gt;\n  units::set_units(ha) |&gt;\n  units::drop_units() |&gt;\n  round()\n\n[1] 7 7 7 7\n\n\n\n\n5.2.2 Spatial subsetting\nNote: this section is adapted from Section 2.12 of Working with Spatial Data in Python. Let’s find the bus stops that are within 150 m of the poi_sf points.\n\nstops_nearby = stops[poi_buffers, ]\nstops_nearby\n\nSimple feature collection with 4 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 16.92882 ymin: 52.44307 xmax: 16.94161 ymax: 52.4653\nGeodetic CRS:  WGS 84\n# A tibble: 4 × 4\n  stop_id stop_name             zone_id            geometry\n    &lt;dbl&gt; &lt;chr&gt;                 &lt;chr&gt;           &lt;POINT [°]&gt;\n1     418 UAM Wydział Geografii A       (16.94108 52.46419)\n2     467 Umultowska            A       (16.92882 52.44426)\n3     468 Umultowska            A       (16.93039 52.44307)\n4     417 UAM Wydział Geografii A        (16.94161 52.4653)\n\n\n\n\n5.2.3 Spatial joins\nSpatial joins can be performed with the st_join() function as follows:\n\npois_joined = st_join(poi_buffers, stops)\npois_joined\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 16.92856 ymin: 52.44223 xmax: 16.95195 ymax: 52.46567\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 5\n  name                                        geometry stop_id stop_name zone_id\n* &lt;chr&gt;                                  &lt;POLYGON [°]&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  \n1 Faculty        ((16.93959 52.46441, 16.93957 52.464…     418 UAM Wydz… A      \n2 Faculty        ((16.93959 52.46441, 16.93957 52.464…     417 UAM Wydz… A      \n3 Hotel ForZa    ((16.94759 52.44224, 16.94762 52.442…      NA &lt;NA&gt;      &lt;NA&gt;   \n4 Hotel Lechicka ((16.93275 52.44435, 16.93275 52.444…     467 Umultows… A      \n5 Hotel Lechicka ((16.93275 52.44435, 16.93275 52.444…     468 Umultows… A      \n6 FairPlayce     ((16.9477 52.461, 16.94765 52.46092,…      NA &lt;NA&gt;      &lt;NA&gt;   \n\n\n\n\n5.2.4 Exercises\n\nCreate a static map of the stops in Poznan, using the stops object created above, with a mapping package of your preference. Set the colour of each stop by zone_id.\n\nBonus: also create an interactive map.\n\nAdvanced: Reproduce the results presented above by following the Python code at geobgu.xyz/presentations/p_2023_ogh/01-vector.html.\n\nWhich language do you prefer for the types of task presented here and why?"
  },
  {
    "objectID": "tidy.html#raster-data-example",
    "href": "tidy.html#raster-data-example",
    "title": "Tidy geographic data",
    "section": "5.3 Raster data example",
    "text": "5.3 Raster data example\nBuilding on the introduction to raster data with Python, this section introduces raster data with the {terra} package.\nLoad it as follows:\n\nlibrary(terra)\n\nterra 1.7.39\n\n\n\nAttaching package: 'terra'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\nRead-in and plot a single raster layer with the following command:\n\nsrc = rast('data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B02.tiff')\nterra::plot(src, col = gray.colors(10))\n\n\n\n\nFigure 7: Plotting a single raster layer with terra\n\n\n\n\nWe will translate the following Python code to R:\nfiles = glob.glob('data/hls/*.tiff')\n\nfiles = list.files(\"data/hls\", pattern = \"tiff\", full.names = TRUE)\nfiles\n\n[1] \"data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B02.tiff\"\n[2] \"data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B03.tiff\"\n[3] \"data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B04.tiff\"\n[4] \"data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B08.tiff\"\n\n\n\nr = rast(files)\nr\n\nclass       : SpatRaster \ndimensions  : 3660, 3660, 4  (nrow, ncol, nlyr)\nresolution  : 30, 30  (x, y)\nextent      : 6e+05, 709800, 5790240, 5900040  (xmin, xmax, ymin, ymax)\ncoord. ref. : WGS 84 / UTM zone 33N (EPSG:32633) \nsources     : HLS.S30.T33UXU.2022200T095559.v2.0.B02.tiff  \n              HLS.S30.T33UXU.2022200T095559.v2.0.B03.tiff  \n              HLS.S30.T33UXU.2022200T095559.v2.0.B04.tiff  \n              HLS.S30.T33UXU.2022200T095559.v2.0.B08.tiff  \nnames       : Blue, Green, Red, NIR_Broad \n\nsummary(r)\n\nWarning: [summary] used a sample\n\n\n      Blue            Green             Red           NIR_Broad   \n Min.   :-213.0   Min.   :  15.0   Min.   : -12.0   Min.   :  56  \n 1st Qu.: 202.0   1st Qu.: 435.0   1st Qu.: 313.0   1st Qu.:2088  \n Median : 319.0   Median : 617.0   Median : 586.0   Median :2469  \n Mean   : 342.3   Mean   : 623.7   Mean   : 669.2   Mean   :2648  \n 3rd Qu.: 434.0   3rd Qu.: 746.0   3rd Qu.: 955.0   3rd Qu.:3174  \n Max.   :4508.0   Max.   :5131.0   Max.   :5428.0   Max.   :6092  \n\n\nWe can plot the result as follows:\n\nplot(r)\n\n\n\n\nFigure 8: Output of plot(r), showing the four bands of the raster layer\n\n\n\n\nAs shown, the result is an object with Blue, Green, Red and NIR bands, in that order. We can select only Red, Green, Blue bands, in that order, as follows:\n\nr_rgb = r[[c(\"Red\", \"Green\", \"Blue\")]]\n\nIf you try plotting the result with plotRGB(r), you will get an error. You can use the stretch argument of the function to stretch the values and avoid errors caused by outliers.\n\nplotRGB(r, stretch = \"lin\")\n\n\n\n\nFigure 9: Plotting a RGB raster layer with terra\n\n\n\n\nWe can also remove outliers with the stretch() or clamp() functions or manually, as shown below:\n\n# r_clamp = clamp(r, 0, 4000)\nr_stretch = stretch(r_rgb, minq = 0.001, maxq = 0.999)\ntop_01pct = quantile(values(r_rgb), probs = 0.999, na.rm = TRUE)\nbottom_01pct = quantile(values(r_rgb), probs = 0.001, na.rm = TRUE)\nr_to_plot = r_rgb\nr_to_plot[r_rgb &gt; top_01pct] = top_01pct\nr_to_plot[r_rgb &lt; bottom_01pct] = bottom_01pct\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Plotting a RGB raster layer with terra, with outliers handled with stretch() (left) and manually (right)\n\n\nSave the combined raster as follows:\n\n# write the r file:\nwriteRaster(r, \"data/hls/combined.tif\", overwrite = TRUE)\nwriteRaster(r_to_plot, \"data/hls/r_to_plot.tif\", overwrite = TRUE)\n\n\n5.3.1 Masking and cropping\nWe can mask the raster with the pol polygon object as follows:\n\npol_projected = sf::st_transform(pol, crs = crs(r))\nr_masked = mask(r, pol_projected)\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\nsummary(r_masked)\n\nWarning: [summary] used a sample\n\n\n      Blue            Green             Red           NIR_Broad     \n Min.   : 351.0   Min.   : 623.0   Min.   : 739.0   Min.   :1165    \n 1st Qu.: 482.0   1st Qu.: 744.8   1st Qu.: 803.0   1st Qu.:2136    \n Median : 526.0   Median : 775.0   Median : 892.0   Median :2338    \n Mean   : 578.1   Mean   : 843.7   Mean   : 963.0   Mean   :2228    \n 3rd Qu.: 569.2   3rd Qu.: 821.2   3rd Qu.: 985.2   3rd Qu.:2485    \n Max.   :1618.0   Max.   :2016.0   Max.   :2231.0   Max.   :2709    \n NA's   :100467   NA's   :100467   NA's   :100467   NA's   :100467  \n\n\nAs shown in the summary of the result, the majority of the values are now NA. That’s how masking works: it sets all values outside the polygon to NA. We can crop the raster to a 500 m buffer around the polygon as follows:\n\nr_cropped = crop(r, sf::st_buffer(pol_projected, dist = 500))\n\nLet’s plot the result, illustrated in Figure 11.\n\ntm_shape(stretch(r_cropped[[c(\"Red\", \"Green\", \"Blue\")]], minq = 0.001, maxq= 0.98)) +\n  tm_rgb() +\n  tm_shape(pol_projected) +\n  tm_borders(col = \"white\", lty = 3) +\n  tm_fill(col = \"red\", alpha = 0.1) +\n  tm_scale_bar(bg.color = \"white\", bg.alpha = 0.6, text.size = 0.8) \n\n\n\n\nFigure 11: Result of plotting a cropped RGB raster layer with the tmap package\n\n\n\n\n\n\n5.3.2 Exercises\n\nExperiment with arguments passed to clamp(), stretch() and plotRGB() to see how they affect the output.\nTry plotting the raster in another program like QGIS, which looks better?\nAdvanced: Reproduce the results presented above by following the Python code at geobgu.xyz/presentations/p_2023_ogh/02-raster.html.\n\nWhich language do you prefer for the types of task presented here and why?\n\nAdvanced: Try plotting the raster with {ggplot2} and {tmap}.\n\nWhich do you prefer and why?"
  },
  {
    "objectID": "tidy.html#tidypolars",
    "href": "tidy.html#tidypolars",
    "title": "Tidy geographic data",
    "section": "6.1 tidypolars",
    "text": "6.1 tidypolars\nIf you want to give this package a spin, run the following command:\n\ninstall.packages(\n  'tidypolars', \n  repos = c('https://etiennebacher.r-universe.dev/bin/linux/jammy/4.3', getOption(\"repos\"))\n)"
  },
  {
    "objectID": "tidy.html#rsgeo",
    "href": "tidy.html#rsgeo",
    "title": "Tidy geographic data",
    "section": "6.2 rsgeo",
    "text": "6.2 rsgeo\nA work in progress is the rsgeo package, which aims to provide an seamless interface between R and the geo Rust crate. This could open the possiblity of calling other high-performance Rust libraries from R, although the package is at an early stage of development and probably not ready for production use.\nWe can check the installation works as follows:\n\ninstall.packages('rsgeo', repos = c('https://josiahparry.r-universe.dev', 'https://cloud.r-project.org'))\n\n\nlibrary(rsgeo)\ncountries_rs  = as_rsgeo(sf::st_geometry(countries_projected))\ncountries_rs\nbench::mark(check = FALSE,\n  sf = sf::st_union(countries_projected),\n  geos = geos::geos_make_collection(geos::geos_unary_union(countries_geos)),\n  rsgeo = rsgeo::union_geoms(countries_rs)\n)"
  },
  {
    "objectID": "tidy.html#arrow",
    "href": "tidy.html#arrow",
    "title": "Tidy geographic data",
    "section": "6.3 Arrow",
    "text": "6.3 Arrow\n\nlibrary(arrow)\n\n# write countries_projected to parquet file:\nwrite_parquet(countries_projected, \"data/countries_projected.parquet\") # Fails"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OpenGeoHub Summer School 2023",
    "section": "",
    "text": "Quarto Publish\nThis repo contains code to support sessions that I will deliver for the OpenGeoHub Summer School 2023.\nAs shown in the course schedule I will deliver the following sessions:\nAbstracts for these sessions are provided below."
  },
  {
    "objectID": "index.html#reproducibility",
    "href": "index.html#reproducibility",
    "title": "OpenGeoHub Summer School 2023",
    "section": "Reproducibility",
    "text": "Reproducibility\nYou can reproduce all of the results and run all the code in this repo. The quickest way to get started if you don’t already have the dependencies is with codespaces.\n\nIf it works you should see something like this:\n\nTo run the code locally download the code, e.g. with the following command after installing GitHub’s CLI tool:\ngh repo clone Robinlovelace/opengeohub2023\nThen open the project in RStudio, VS Code, and start looking at and running the code. You should be able to reproduce the rendered website interactively with the following command:\nquarto preview\nYou can also run the code in this repo in the Docker image hosted at https://github.com/Robinlovelace/opengeohub2023/pkgs/container/opengeohub2023 as follows, with the -v flag to mount the current directory in the container:\ndocker run -it -v $(pwd):/workspace opengeohub2023:latest\nIf you have VS Code installed you should be able to ‘Reopen in Container’ (not fully tested locally)."
  },
  {
    "objectID": "index.html#tidy-geographic-data-with-sf-dplyr-ggplot2-geos-and-friends",
    "href": "index.html#tidy-geographic-data-with-sf-dplyr-ggplot2-geos-and-friends",
    "title": "OpenGeoHub Summer School 2023",
    "section": "Tidy geographic data with sf, dplyr, ggplot2, geos and friends",
    "text": "Tidy geographic data with sf, dplyr, ggplot2, geos and friends\n\nThis lecture will provide an introduction to working with geographic data using R in a ‘tidy’ way. It will focus on using the sf package to read, write, manipulate, and plot geographic data in combination with the tidyverse metapackage. Why use the sf package with the tidyverse? The lecture will outline some of the ideas underlying the tidyverse and how they can speed-up data analysis pipelines, while making data analysis code easier to read and write. We will see how the following lines\nlibrary(sf)\nlibrary(tidyverse)\ncan provide a foundation on which the many geographic data analysis problems can be solved. The lecture will also cover on more recently developed packages that integrate with the tidyverse to a greater and lesser extent. We will look at how the geos package, which provides a simple and high-performance interface to the GEOS library for performing geometric operations on geographic data, integrates with the tidyverse. The tidyverse is not the right tool for every data analysis task and we touch on alternatives for working with raster data, with reference to the terra package, and alternative frameworks such as data.table. Finally, we will also look at how the ‘tidy’ philosophy could be implemented in other programming languages, such as Python.\nThe focus throughout will be on practical skills and using packages effectively within the wider context of project management tools, integrated development environments (we recommend VS Code with appropriate extensions or RStudio), and version control systems."
  },
  {
    "objectID": "index.html#processing-large-openstreetmap-datasets-for-geocomputation",
    "href": "index.html#processing-large-openstreetmap-datasets-for-geocomputation",
    "title": "OpenGeoHub Summer School 2023",
    "section": "Processing large OpenStreetMap datasets for geocomputation",
    "text": "Processing large OpenStreetMap datasets for geocomputation\nOpenStreetMap (OSM) is a free and openly editable map of the world. Like Wikipedia and unlike government or corperation maintained datasets, OSM is created and maintained by a community of volunteers, making it the premier decentralized and fastest evolving source of geographic vector data focussed on features relevant to human activity (e.g. roads, buildings, cafes) on planet Earth. Unlike Wikipedia, every data point in OSM has a geographic location and attributes must be structured as key-value pairs. OSM is a rich source of data for geocomputation, but the decentralized nature of the project and the sheer volume of data. ‘Planet.osm’ now has more nodes than there are people on Earth, with more than 8 billion nodes, and the rate of data creation is increasing as the community grows, to 10 million users in early 2023. The size and rapid evolution of OSM are great strengths, democratising geographic knowledge and ensuring resilience. However, these features can make it difficult to work with OSM data.\nThis lecture will provide an introduction to working with OSM and will cover the following:\n\nHow and where to download OSM data\nHow to process small amounts of OSM data using the osmdata R package\nHow to process large OSM ‘extracts’ data with the osmextract R package\nOther command line tools for working with OSM data, including the mature and widely used osmium tool, the pyrosm Python package and the osm2streets web application and Rust codebase\n\nFinally, the lecture will outline ideas for using OSM data. It will conclude with a call to action, inspiring the use of this rich resource to support policy objectives such as the fast and fair decarbonisation of the global economy as societies transition away from inefficient, polluting and costly fossil fuels."
  },
  {
    "objectID": "index.html#reproducibility-1",
    "href": "index.html#reproducibility-1",
    "title": "OpenGeoHub Summer School 2023",
    "section": "Reproducibility",
    "text": "Reproducibility\nTo install the dependencies for this repo, run the following command:\nremotes::install_github(\"robinlovelace/opengeohub2023\")\nThis repo also uses the renv package to manage dependencies. We saved the dependencies with the following command:\n\nrenv::snapshot()\n\nCode was generated from the .qmd files using the following commands:\n\nf = c(\"tidy.qmd\", \"osm.qmd\")\nf_r = gsub(\".qmd\", \".R\", f)\nfor(i in seq_along(f)) {\n  knitr::purl(f[i], f_r[i])\n}\n\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\nThe content below was rendered from README.qmd in the robinlovelace/opengeohub23 GitHub repository where you can find the source code for this website."
  },
  {
    "objectID": "note-lecture1-ogh.html",
    "href": "note-lecture1-ogh.html",
    "title": "Untitled",
    "section": "",
    "text": "These are the packages we’ll use:\nlibrary(sf)\n\nLinking to GEOS 3.10.2, GDAL 3.4.1, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nknitr::opts_chunk$set(eval = FALSE)\nlibrary(spData)\nnames(world)\nworld\npoland = world[world$name_long == \"Poland\", 1]\ndim(poland)\nnames(poland)\npoland_df = sf::st_drop_geometry(poland)\nclass(poland)\nclass(poland_df)\nplot(poland)\nplot(poland_df)\nTidyverse way:\npoland = world |&gt;\n  filter(name_long == \"Poland\") |&gt;\n  select(name_long, pop, area_km2)"
  },
  {
    "objectID": "note-lecture1-ogh.html#data-from-poznan",
    "href": "note-lecture1-ogh.html#data-from-poznan",
    "title": "Untitled",
    "section": "Data from Poznan",
    "text": "Data from Poznan\n\nu = \"https://github.com/Robinlovelace/opengeohub2023/releases/download/data/data.zip\"\nf = basename(u)\nf\noptions(timeout = 600)\ndownload.file(url = u, f)\nunzip(f)\n\n\nlist.files(\"data/\")\nlist.files(\"data/osm\")\n\n\npol_all = read_sf(\"data/osm/gis_osm_transport_a_free_1.shp\")\npol_all\nplot(pol_all)\n\n\npol_bus = pol_all |&gt; \n  filter(str_detect(name, \"bus\"))\n\npol_bus_station = pol_all |&gt; \n  filter(fclass == \"bus_station\")\n\nmapview::mapview(pol_bus_station)\n\npol = pol_all |&gt; \n  filter(str_detect(name, \"Port*.+P\"))\n\npol |&gt;\n  ggplot() +\n  geom_sf()\n\nlibrary(tmap)\ntmap_mode(\"view\")\ntm_shape(pol) +\n  tm_borders()\n\nCreate pois:\n\npoi_df = tribble(\n  ~name, ~lon, ~lat,\n  \"Faculty\",        16.9418, 52.4643,\n  \"Hotel ForZa\",    16.9474, 52.4436,\n  \"Hotel Lechicka\", 16.9308, 52.4437,\n  \"FairPlayce\",     16.9497, 52.4604\n)\npoi_df\npoi_sf = sf::st_as_sf(poi_df, coords = c(\"lon\", \"lat\"))\nsf::st_crs(poi_sf) = \"EPSG:4326\"\n\n\nstop_raw = read_csv(\"data/gtfs/stops.txt\")\nstops_df = stop_raw |&gt; \n  select(-stop_code)\nstops = sf::st_as_sf(stops_df, coords = c(\"stop_lon\", \"stop_lat\"))\nsf::st_crs(stops)\nsf::st_crs(stops) = \"EPSG:4326\"\nsf::st_crs(stops)\n\n\npois_buffer = sf::st_buffer(poi_sf, 150)\nstops_in_buffer = stops[pois_buffer, ]\n\nstops_not_in_buffer = stops[pois_buffer, , op = sf::st_disjoint]\nnrow(stops_in_buffer)\nnrow(stops_not_in_buffer)\n\nstops_not_in_buffer = stops |&gt; \n  filter(!stop_id %in% stops_in_buffer$stop_id)\nnrow(stops)\nnrow(stops_in_buffer)\ncrsuggest::suggest_crs(stops_in_buffer)\n\nstops_not_in_buffer2 = sf::st_difference(stops, sf::st_union(pois_buffer))\n\nplot(pois_buffer$geometry[1])\n\npois_buffer2 = stplanr::geo_buffer(poi_sf, dist = 150)\nplot(pois_buffer2$geometry[1])\n\npois_joined = sf::st_join(pois_buffer, stops)\n\nstops_joined = stops |&gt; \n  filter(stop_id %in% pois_joined$stop_id)\n\nstops_joined$geometry_txt = sf::st_as_text(stops_joined$geometry)\n\npois_joined2 = left_join(\n  pois_joined,\n  stops_joined |&gt;\n    select(stop_id, geometry_txt) |&gt; \n  sf::st_drop_geometry()\n  )"
  },
  {
    "objectID": "tidy-slides.html#session-overview",
    "href": "tidy-slides.html#session-overview",
    "title": "Tidy geographic data",
    "section": "Session overview",
    "text": "Session overview\n\nSource: pretalx.earthmonitor.org/opengeohub-summer-school-2023/schedule/v/0.7/\n\nParallel to the Python session."
  },
  {
    "objectID": "tidy-slides.html#about-me",
    "href": "tidy-slides.html#about-me",
    "title": "Tidy geographic data",
    "section": "About me",
    "text": "About me\n\n\n\nAssociate Professor, University of Leeds\nHead of Data and Digital at Active Travel England\nAuthor of Geocomputation with R\nResearch: geocomputation + transport decarbonisation\nResearch question: where to build bike lanes?\n\n\n\nSource: www.npt.scot"
  },
  {
    "objectID": "tidy-slides.html#from-research-to-impact",
    "href": "tidy-slides.html#from-research-to-impact",
    "title": "Tidy geographic data",
    "section": "From research to impact",
    "text": "From research to impact"
  },
  {
    "objectID": "tidy-slides.html#geocomputation-to-tackle-the-climate-crisis",
    "href": "tidy-slides.html#geocomputation-to-tackle-the-climate-crisis",
    "title": "Tidy geographic data",
    "section": "Geocomputation to tackle the climate crisis",
    "text": "Geocomputation to tackle the climate crisis"
  },
  {
    "objectID": "tidy-slides.html#system-dependencies",
    "href": "tidy-slides.html#system-dependencies",
    "title": "Tidy geographic data",
    "section": "System dependencies",
    "text": "System dependencies\n\nSource: Pebesma (2018)\n\nSystem dependencies."
  },
  {
    "objectID": "tidy-slides.html#system-dependencies-code",
    "href": "tidy-slides.html#system-dependencies-code",
    "title": "Tidy geographic data",
    "section": "System dependencies: code",
    "text": "System dependencies: code\n\nsf startup message:\n\n\nsf::sf_extSoftVersion()\n\n          GEOS           GDAL         proj.4 GDAL_with_GEOS     USE_PROJ_H \n      \"3.10.2\"        \"3.4.1\"        \"8.2.1\"         \"true\"         \"true\" \n          PROJ \n       \"8.2.1\" \n\n\n\nOn Linux sf uses system installations of GDAL, GEOS and PROJ.4:\n\n\ngdalinfo --version\nwhich gdal-config\n\nGDAL 3.4.1, released 2021/12/27\n/usr/bin/gdal-config\n\n\n\nOn Windows, sf ships with binary versions installed"
  },
  {
    "objectID": "tidy-slides.html#development-environments",
    "href": "tidy-slides.html#development-environments",
    "title": "Tidy geographic data",
    "section": "Development environments",
    "text": "Development environments\n\n\nRStudio\n\nPro: works out of the box\nPro: Great R autocomplete\nPro: Features for data science + R package development\nCon: A bit R specific\n\nVS Code\n\nPro: Works with many languages\nPro: Unbeatable ecosystem of extensions\nPro: Advanced features such as copilot + works in Codespaces\nCon: A bit fiddly to set up, rough edges when using R"
  },
  {
    "objectID": "tidy-slides.html#rstudio-1",
    "href": "tidy-slides.html#rstudio-1",
    "title": "Tidy geographic data",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "tidy-slides.html#vs-code-1",
    "href": "tidy-slides.html#vs-code-1",
    "title": "Tidy geographic data",
    "section": "VS Code",
    "text": "VS Code"
  },
  {
    "objectID": "tidy-slides.html#results",
    "href": "tidy-slides.html#results",
    "title": "Tidy geographic data",
    "section": "Results",
    "text": "Results\n\n\n\nOn Twitter:\n\n\n\n\n\nOn Mastodon:"
  },
  {
    "objectID": "tidy-slides.html#on-mattermost",
    "href": "tidy-slides.html#on-mattermost",
    "title": "Tidy geographic data",
    "section": "On Mattermost",
    "text": "On Mattermost"
  },
  {
    "objectID": "tidy-slides.html#mattermost-results",
    "href": "tidy-slides.html#mattermost-results",
    "title": "Tidy geographic data",
    "section": "Mattermost results",
    "text": "Mattermost results"
  },
  {
    "objectID": "tidy-slides.html#mattermost-results-2",
    "href": "tidy-slides.html#mattermost-results-2",
    "title": "Tidy geographic data",
    "section": "Mattermost results 2…",
    "text": "Mattermost results 2…"
  },
  {
    "objectID": "tidy-slides.html#key-features-of-sf",
    "href": "tidy-slides.html#key-features-of-sf",
    "title": "Tidy geographic data",
    "section": "Key features of sf",
    "text": "Key features of sf\n\nSource: Lovelace, Nowosad, and Muenchow (2019)"
  },
  {
    "objectID": "tidy-slides.html#sf-functions",
    "href": "tidy-slides.html#sf-functions",
    "title": "Tidy geographic data",
    "section": "sf functions",
    "text": "sf functions\n\nSource: Pebesma (2018)"
  },
  {
    "objectID": "tidy-slides.html#practical-1330-1430",
    "href": "tidy-slides.html#practical-1330-1430",
    "title": "Tidy geographic data",
    "section": "Practical (~13:30-14:30)",
    "text": "Practical (~13:30-14:30)\nWork through the code in Section 2 and 3 at ogh23.robinlovelace.net/tidy and answer the questions at your own pace.\n\nremotes::install_github(\"robinlovelace/opengeohub2023\")\n\n\nsapply(pkgs, require, character.only = TRUE)\n\n       sf tidyverse      geos    spData \n     TRUE      TRUE      TRUE      TRUE"
  },
  {
    "objectID": "tidy-slides.html#geos",
    "href": "tidy-slides.html#geos",
    "title": "Tidy geographic data",
    "section": "geos",
    "text": "geos"
  },
  {
    "objectID": "tidy-slides.html#rsgeo",
    "href": "tidy-slides.html#rsgeo",
    "title": "Tidy geographic data",
    "section": "rsgeo",
    "text": "rsgeo"
  },
  {
    "objectID": "tidy-slides.html#rsgeo-ii",
    "href": "tidy-slides.html#rsgeo-ii",
    "title": "Tidy geographic data",
    "section": "rsgeo II",
    "text": "rsgeo II"
  },
  {
    "objectID": "tidy-slides.html#tidyverse-alternatives",
    "href": "tidy-slides.html#tidyverse-alternatives",
    "title": "Tidy geographic data",
    "section": "tidyverse alternatives",
    "text": "tidyverse alternatives"
  },
  {
    "objectID": "tidy-slides.html#comparing-r-with-python",
    "href": "tidy-slides.html#comparing-r-with-python",
    "title": "Tidy geographic data",
    "section": "Comparing R with Python",
    "text": "Comparing R with Python\nInspiration: Working with Spatial Data in Python materials"
  },
  {
    "objectID": "tidy-slides.html#vector-data-in-rpython",
    "href": "tidy-slides.html#vector-data-in-rpython",
    "title": "Tidy geographic data",
    "section": "Vector data in R/Python",
    "text": "Vector data in R/Python\nAim: cross-compare approaches\nSource: Python version and R version"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "",
    "text": "In this blog post, we talk about our experience teaching R and Python for geocomputation. The focus of the blog post is on geographic vector data, meaning points, lines, polygons (and their ‘multi’ variants) and the attributes associated with them. Geographic data analysis is a broad topic and in a later post we will cover raster data, meaning gridded data such as satellite images.\n The context of this blog post is the OpenGeoHub Summer School 2023 which has courses on R, Python and Julia. The size and the diversity of the event has grown over the years. Noting that many events focus on just one language, and the advantages of diversity of languages and approaches, we wanted to follow-up in a blog post that could be useful to others.\nOpenGeoHub 2023 was also a unique chance for the authors of the in-progress open source book, Geocomputation with Python to meet in person: the first time we have all been in one place at the same time.\nThe post is based on the following lecture notes, which we recommend checking out for deeper dives into the R and Python implementations of geocomputation:\n\nTidy geographic data with sf, dplyr, ggplot2, geos and friends\nWorking with spatial data in Python"
  },
  {
    "objectID": "blog.html#loading-packages",
    "href": "blog.html#loading-packages",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Loading packages",
    "text": "Loading packages\nWe will start by loading core packages for working with geographic vector and attribute data. See detailed description of R and Python implementations in the respective lecture note sections.\n\nPythonRJulia\n\n\n\nimport pandas as pd\nfrom shapely import Point\nimport geopandas as gpd\n\n\n\n\n\nlibrary(sf)\nlibrary(tidyverse)\nlibrary(tmap)\n\n\n\nusing GeoDataFrames"
  },
  {
    "objectID": "blog.html#creating-geographic-data",
    "href": "blog.html#creating-geographic-data",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Creating geographic data",
    "text": "Creating geographic data\nThe following commands create geographic datasets ‘from scratch’ representing coordinates of a the faculty where the Summer School takes place, and few hotels, in Poznan, Poland. Most projects start with pre-generated data, but it’s useful to create datasets to understand data structures.\n\nPythonR\n\n\n\npoi = gpd.GeoDataFrame([\n    {\"name\": \"Faculty\",        \"geometry\": Point(16.9418, 52.4643)},\n    {\"name\": \"Hotel ForZa\",    \"geometry\": Point(16.9474, 52.4436)},\n    {\"name\": \"Hotel Lechicka\", \"geometry\": Point(16.9308, 52.4437)},\n    {\"name\": \"FairPlayce\",     \"geometry\": Point(16.9497, 52.4604)},\n], crs=4326)\n\n\n\n\npoi_df = tribble(\n  ~name, ~lon, ~lat,\n  \"Faculty\",        16.9418, 52.4643,\n  \"Hotel ForZa\",    16.9474, 52.4436,\n  \"Hotel Lechicka\", 16.9308, 52.4437,\n  \"FairPlayce\",     16.9497, 52.4604\n)\npoi_sf = sf::st_as_sf(poi_df, coords = c(\"lon\", \"lat\"), crs = \"EPSG:4326\")\n\n\n\n\n\nDownloading data\nThe following commands download data from the internet.\n\nPythonRJulia\n\n\n\nimport urllib.request\nimport zipfile\nimport os\nu = \"https://github.com/Robinlovelace/opengeohub2023/releases/download/data/data.zip\"\nf = os.path.basename(u)\nif not os.path.exists(\"data\"):\n    urllib.request.urlretrieve(u, f)\n\n\n\n\nu = \"https://github.com/Robinlovelace/opengeohub2023/releases/download/data/data.zip\"\nf = basename(u)\nif (!dir.exists(\"data\")) {\n  download.file(u, f)\n}\n\n\n\nusing Downloads\nu = \"https://github.com/Robinlovelace/opengeohub2023/releases/download/data/data.zip\"\nf = basename(u)\nif !isfile(f)\n    download(u, f)\nend\nNote that we can read directly from ZIP files with R, Python, and Julia thanks to the GDAL Virtual File System."
  },
  {
    "objectID": "blog.html#unzipping-data",
    "href": "blog.html#unzipping-data",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Unzipping data",
    "text": "Unzipping data\nWe can unzip the data in R and Python: it contains spatial information about bus stops.\n\nPythonR\n\n\n\nwith zipfile.ZipFile(f, 'r') as zip_ref:\n    zip_ref.extractall()\n\n\n\n\nunzip(f)"
  },
  {
    "objectID": "blog.html#reading-and-printing-geographic-data",
    "href": "blog.html#reading-and-printing-geographic-data",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Reading and printing geographic data",
    "text": "Reading and printing geographic data\nAs shown below, Python and R implemenations to import a shapefile are similar. Note: we recommend using open file formats such as GeoPackage (.gpkg), as outlined in Geocomputation with R and Geocomputation with Python.\n\nPythonRJulia\n\n\n\npol_all = gpd.read_file(\"zip://data.zip!data/osm/gis_osm_transport_a_free_1.shp\")\npol_all\n\n         osm_id  ...                                           geometry\n0      27923283  ...  POLYGON ((16.84088 52.42479, 16.84112 52.42511...\n1      28396243  ...  POLYGON ((16.96750 52.32743, 16.96802 52.32807...\n2      28396249  ...  POLYGON ((16.98029 52.32399, 16.98038 52.32409...\n3      28396250  ...  POLYGON ((16.97407 52.32418, 16.97420 52.32433...\n4      30164579  ...  POLYGON ((16.71011 53.16458, 16.71041 53.16478...\n..          ...  ...                                                ...\n277  1073517768  ...  POLYGON ((16.83966 51.60933, 16.83996 51.60941...\n278  1098015810  ...  POLYGON ((16.90579 52.43677, 16.90589 52.43672...\n279  1101813658  ...  POLYGON ((16.52227 52.34424, 16.52230 52.34425...\n280  1146503680  ...  POLYGON ((16.90591 52.42877, 16.90593 52.42878...\n281  1157127550  ...  POLYGON ((18.07060 51.74824, 18.07062 51.74826...\n\n[282 rows x 5 columns]\n\n\n\n\n\npol_all = sf::read_sf(\"/vsizip/data.zip/data/osm/gis_osm_transport_a_free_1.shp\")\npol_all\n\nSimple feature collection with 282 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 15.76877 ymin: 51.42587 xmax: 18.51031 ymax: 53.52821\nGeodetic CRS:  WGS 84\n# A tibble: 282 × 5\n   osm_id    code fclass          name                                  geometry\n   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;                            &lt;POLYGON [°]&gt;\n 1 27923283  5656 apron           &lt;NA&gt;                 ((16.84088 52.42479, 16.…\n 2 28396243  5656 apron           &lt;NA&gt;                 ((16.9675 52.32743, 16.9…\n 3 28396249  5656 apron           &lt;NA&gt;                 ((16.98029 52.32399, 16.…\n 4 28396250  5656 apron           &lt;NA&gt;                 ((16.97407 52.32418, 16.…\n 5 30164579  5656 apron           &lt;NA&gt;                 ((16.71011 53.16458, 16.…\n 6 32225811  5601 railway_station Czerwonak            ((16.9798 52.46868, 16.9…\n 7 36204378  5622 bus_station     &lt;NA&gt;                 ((16.95469 52.40964, 16.…\n 8 50701732  5651 airport         Lądowisko Poznań-Be… ((17.19788 52.53491, 17.…\n 9 55590985  5622 bus_station     Dworzec PKS-stanowi… ((17.20243 52.80927, 17.…\n10 56064358  5651 airport         Port lotniczy Zielo… ((15.76877 52.13175, 15.…\n# ℹ 272 more rows\n\n\n\n\ndf = GeoDataFrames.read(\"/vsizip/data.zip/data/osm/gis_osm_transport_a_free_1.shp\")\ndf\n\n\n\n\nNote: in R, you can read-in the dataset from the URL in a single line of code without first downloading the zip file:\n\nuz = paste0(\"/vsizip//vsicurl/\", u, \"/data/osm/gis_osm_transport_a_free_1.shp\")\npol_all = sf::read_sf(uz)"
  },
  {
    "objectID": "blog.html#subsetting-by-attributes",
    "href": "blog.html#subsetting-by-attributes",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Subsetting by attributes",
    "text": "Subsetting by attributes\nThe following commands select a subset of the data based on attribute values (looking for a specific string in the name column).\n\nPythonR\n\n\n\npol = pol_all[pol_all['name'].str.contains('Port*.+Poz', na=False)]\npol\n\n        osm_id  ...                                           geometry\n116  342024881  ...  POLYGON ((16.80040 52.42494, 16.80060 52.42533...\n\n[1 rows x 5 columns]\n\n\n\n\n\npol = pol_all |&gt;\n  filter(str_detect(name, \"Port*.+Poz\"))\npol\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 16.8004 ymin: 52.41373 xmax: 16.85458 ymax: 52.42736\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  osm_id     code fclass  name                                          geometry\n* &lt;chr&gt;     &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;                                    &lt;POLYGON [°]&gt;\n1 342024881  5651 airport Port Lotniczy Poznań-Ławica… ((16.8004 52.42494, 16.8…"
  },
  {
    "objectID": "blog.html#basic-plotting",
    "href": "blog.html#basic-plotting",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Basic plotting",
    "text": "Basic plotting\nThe following commands plot the data. Note that by default, R’s plot() method for {sf} objects creates a plot for each column in the data (up to 9 by default). \n\nPythonR\n\n\n\npol.plot();\n\n\n\n\n\n\n\nplot(pol)\n\n\n\n\n\n\n\nThe arguments needed to change the colour of the fill and border are different in R and Python, but the results are similar.\n\nPythonR\n\n\n\npol.plot(color='none', edgecolor='black');\n\n\n\n\n\n\n\nplot(st_geometry(pol), col = \"white\", border = \"black\")"
  },
  {
    "objectID": "blog.html#creating-geographic-data-frames-from-a-csv-file",
    "href": "blog.html#creating-geographic-data-frames-from-a-csv-file",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Creating geographic data frames from a CSV file",
    "text": "Creating geographic data frames from a CSV file\nThe following commands create a geographic data frame from a CSV file. Note that two steps—creating the geometry column and combining it with the original table, hereby combined into one complex expression—are needed to convert a DataFrame to a GeoDataFrame in Python, whereas in R the sf::st_as_sf() function can be used to convert a data.frame to a spatial data frame directly.\n\nPythonR\n\n\n\n# Unzip the data.zip file:\nwith zipfile.ZipFile(f, 'r') as zip_ref:\n    zip_ref.extractall(\"data\")\nstops = pd.read_csv(\"data/gtfs/stops.txt\")\nstops = gpd.GeoDataFrame(\n    stops.drop(columns=['stop_lon', 'stop_lat', 'stop_code']),\n    geometry = gpd.points_from_xy(stops.stop_lon, stops.stop_lat),\n    crs = 4326)\nstops\n\n      stop_id  ...                   geometry\n0        2186  ...  POINT (17.04263 52.32684)\n1         355  ...  POINT (16.86888 52.46234)\n2        4204  ...  POINT (16.78629 52.47810)\n3        3885  ...  POINT (16.72401 52.47590)\n4         494  ...  POINT (16.93085 52.43616)\n...       ...  ...                        ...\n2916     2099  ...  POINT (16.65026 52.47006)\n2917     3915  ...  POINT (16.98360 52.38233)\n2918     3876  ...  POINT (16.52949 52.49770)\n2919      594  ...  POINT (16.80900 52.43642)\n2920     1190  ...  POINT (16.99819 52.44124)\n\n[2921 rows x 4 columns]\n\n\n\n\n\nstops = read_csv(\"data/gtfs/stops.txt\") |&gt;\n  select(-stop_code) |&gt;\n  st_as_sf(coords = c(\"stop_lon\", \"stop_lat\"), crs = \"EPSG:4326\")\nstops\n\nSimple feature collection with 2921 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 16.48119 ymin: 52.15166 xmax: 17.27693 ymax: 52.58723\nGeodetic CRS:  WGS 84\n# A tibble: 2,921 × 4\n   stop_id stop_name              zone_id            geometry\n *   &lt;dbl&gt; &lt;chr&gt;                  &lt;chr&gt;           &lt;POINT [°]&gt;\n 1    2186 Żerniki/Skrzyżowanie   B       (17.04263 52.32684)\n 2     355 Sucholeska             A       (16.86888 52.46234)\n 3    4204 Pawłowicka             A        (16.78629 52.4781)\n 4    3885 Kobylniki/Karolewska   B        (16.72401 52.4759)\n 5     494 Połabska               A       (16.93085 52.43616)\n 6    2040 Tarnowo Pdg/Karolewo I C       (16.68462 52.46915)\n 7    3736 Komorniki/Kryształowa  B        (16.78291 52.3478)\n 8    3932 Unii Lubelskiej        A        (16.9497 52.37239)\n 9    2795 Potasze/Jodłowa        C       (17.02994 52.52445)\n10    3861 Miękowo/Stokrotkowa    C       (16.98954 52.49024)\n# ℹ 2,911 more rows"
  },
  {
    "objectID": "blog.html#plotting-attributes-and-layers",
    "href": "blog.html#plotting-attributes-and-layers",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Plotting attributes and layers",
    "text": "Plotting attributes and layers\nThe following commands plot the bus stops loaded in the previous step. Note that the tmap package is hereby used in R to create these more advanced plots, as it also supports interactive mapping (see below).\n\nPythonR\n\n\n\nstops.plot(markersize=1, column='zone_id', legend=True);\n\n\n\n\n\n\n\ntm_shape(stops) +\n  tm_symbols(size = 0.1, col = \"zone_id\")\n\n\n\n\n\n\n\nWe can add basic overlays in both languages as follows.\n\nPythonR\n\n\n\nbase = stops.plot(markersize=0.1)\npoi.plot(ax=base, color='red');\n\n\n\n\n\n\n\n\nplot(stops$geometry, col = \"grey\", pch = 20, cex = 0.5)\nplot(poi_sf$geometry, col = \"red\", add = TRUE)"
  },
  {
    "objectID": "blog.html#interactive-plots",
    "href": "blog.html#interactive-plots",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Interactive plots",
    "text": "Interactive plots\nThe following commands create interactive plots, in Python and R respectively. The Python code requires the folium and mapclassify packages, which are not installed by default when you install geopandas. Note that with tmap, you can use the same code to create static and interactive plots, by changing the tmap_mode().\n\nPythonR\n\n\n\nstops.explore(column='zone_id', legend=True, cmap='Dark2')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\n\ntmap_mode(\"view\")\ntm_shape(stops) +\n  tm_symbols(size = 0.1, col = \"zone_id\")"
  },
  {
    "objectID": "blog.html#reprojecting-data",
    "href": "blog.html#reprojecting-data",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Reprojecting data",
    "text": "Reprojecting data\nThe following commands reproject the data to a local projected Coordinate Reference System (CRS).\n\nPythonR\n\n\n\npoi.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\npoi_projected = poi.to_crs(2180)\nstops_projected = stops.to_crs(2180)\n\n\n\n\nst_crs(poi_sf)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\npoi_projected = st_transform(poi_sf, 2180)\nstops_projected = st_transform(stops, 2180)"
  },
  {
    "objectID": "blog.html#buffers",
    "href": "blog.html#buffers",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Buffers",
    "text": "Buffers\nThe following commands create buffers around the points. Note that R allows buffer to be created directly from a spatial data frame with geographic (lon/lot) coordinates thanks to its integration with Google’s S2 spherical geometry engine, as outlined in Geocomputation with R. For buffer operations to work in Python you must reproject the data first (which we did, see above) (although there are plans for geopandas to support a spherical geometry backend at some point, as discussed in issue #2098).\n\nPythonR\n\n\n\nTo create a new vector layers named poi_buffer, in both languages, we can do the following.\n\npoi_buffer = poi.copy()\npoi_buffer.geometry = poi_projected.buffer(150).to_crs(4326)\n\n\n\n\npoi_buffer = st_buffer(poi_sf, 150)"
  },
  {
    "objectID": "blog.html#calculating-distances-and-areas",
    "href": "blog.html#calculating-distances-and-areas",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Calculating distances and areas",
    "text": "Calculating distances and areas\nAn interesting difference between R and Python is that the former uses the units package to store units, making it easy to convert between them, as outlined in the buffers section of the R lecture notes.\n\nPythonR\n\n\n\npoi_buffer.to_crs(2180).area\n\n0    70572.341037\n1    70572.341037\n2    70572.341037\n3    70572.341037\ndtype: float64\n\n\n\n\n\nst_area(poi_buffer)\n\nUnits: [m^2]\n[1] 71656.68 71644.28 71656.92 71667.15"
  },
  {
    "objectID": "blog.html#spatial-subsetting",
    "href": "blog.html#spatial-subsetting",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Spatial subsetting",
    "text": "Spatial subsetting\nCode to subset the bus stops within the buffered poi points is shown below. The R code is more concise because there is a special [ notation for the specific case of subsetting by intersection. In Python you must undertake the explicit steps, which are applicable to any predicate in both languages:\n\nTake the unary union of the buffered points before subsetting\nCreate a boolean Series object with the .intersects or other method, and use the boolean Series to subset the data (rather than another geographic object)\n\n\nPythonR\n\n\n\npoi_union = poi_buffer.unary_union\nsel = stops.intersects(poi_union)\nstops_in_b = stops[sel]\nstops_in_b\n\n      stop_id              stop_name zone_id                   geometry\n295       418  UAM Wydział Geografii       A  POINT (16.94108 52.46419)\n681       467             Umultowska       A  POINT (16.92882 52.44426)\n1724      468             Umultowska       A  POINT (16.93039 52.44307)\n1861      417  UAM Wydział Geografii       A  POINT (16.94161 52.46530)\n\n\n\n\n\nstops_in_b = stops[poi_buffer, ]\nstops_in_b\n\nSimple feature collection with 4 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 16.92882 ymin: 52.44307 xmax: 16.94161 ymax: 52.4653\nGeodetic CRS:  WGS 84\n# A tibble: 4 × 4\n  stop_id stop_name             zone_id            geometry\n    &lt;dbl&gt; &lt;chr&gt;                 &lt;chr&gt;           &lt;POINT [°]&gt;\n1     418 UAM Wydział Geografii A       (16.94108 52.46419)\n2     467 Umultowska            A       (16.92882 52.44426)\n3     468 Umultowska            A       (16.93039 52.44307)\n4     417 UAM Wydział Geografii A        (16.94161 52.4653)"
  },
  {
    "objectID": "blog.html#spatial-joins",
    "href": "blog.html#spatial-joins",
    "title": "Geographic data analysis in R and Python: comparing code and outputs for vector data",
    "section": "Spatial joins",
    "text": "Spatial joins\nSpatial joins are implemented with similar functions in R and Python and the outputs are the same. See the Python and R tutorials, and in Geocomputation with R Section 4.2.4 and Geocomputation with Python 3.3.4 for more details.\n\nPythonR\n\n\n\npoi_buffer.sjoin(stops, how='left')\n\n             name  ... zone_id\n0         Faculty  ...       A\n0         Faculty  ...       A\n1     Hotel ForZa  ...     NaN\n2  Hotel Lechicka  ...       A\n2  Hotel Lechicka  ...       A\n3      FairPlayce  ...     NaN\n\n[6 rows x 6 columns]\n\n\n\n\n\nst_join(poi_buffer, stops)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 16.92856 ymin: 52.44223 xmax: 16.95195 ymax: 52.46567\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 5\n  name                                        geometry stop_id stop_name zone_id\n* &lt;chr&gt;                                  &lt;POLYGON [°]&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  \n1 Faculty        ((16.93959 52.46441, 16.93957 52.464…     418 UAM Wydz… A      \n2 Faculty        ((16.93959 52.46441, 16.93957 52.464…     417 UAM Wydz… A      \n3 Hotel ForZa    ((16.94759 52.44224, 16.94762 52.442…      NA &lt;NA&gt;      &lt;NA&gt;   \n4 Hotel Lechicka ((16.93275 52.44435, 16.93275 52.444…     467 Umultows… A      \n5 Hotel Lechicka ((16.93275 52.44435, 16.93275 52.444…     468 Umultows… A      \n6 FairPlayce     ((16.9477 52.461, 16.94765 52.46092,…      NA &lt;NA&gt;      &lt;NA&gt;"
  }
]